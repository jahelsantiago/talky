This application was created using BERT (Bidirectional Encoder Representations for transformers), a transformer encoder architecture that has proven to be successful in NLP tasks. For this application it was used MobileBert , a modification of the original one which is a lighter and faster version.

The model takes a reference text, and a question and returns a segment of the reference text that most likely answers the given question.

This web application was created using Tensorflow.js to run the BERT model in the browser, the front-end was developed with React.js and Material UI.
